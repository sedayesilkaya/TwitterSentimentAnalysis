{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "url=\"https://twitter.com\"\n",
    "\n",
    "browser.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "girisYap =  browser.find_element_by_css_selector(\"#react-root div.css-1dbjc4n.r-13awgt0.r-12vffkv div.css-1dbjc4n.r-13awgt0.r-12vffkv div.css-1dbjc4n.r-13qz1uu.r-417010 header.css-1dbjc4n.r-1g40b8q div.css-1dbjc4n.r-14lw9ot.r-uvzvve.r-rull8r.r-qklmqi.r-1d2f490.r-1xcajam.r-zchlnj.r-ipm5af.r-1siec45.r-o7ynqc.r-axxi2z.r-136ojw6 div.css-1dbjc4n.r-1jgb5lz.r-sb58tz.r-13qz1uu div.css-1dbjc4n.r-14lw9ot.r-18u37iz.r-1h3ijdo.r-1wtj0ep.r-utggzx.r-rjfia.r-136ojw6 div.css-1dbjc4n.r-18u37iz.r-16y2uox.r-1h3ijdo.r-58zi21 div.css-1dbjc4n.r-1awozwy.r-1pz39u2.r-18u37iz.r-16y2uox div.css-1dbjc4n.r-16y2uox a.css-4rbku5.css-18t94o4.css-1dbjc4n.r-1niwhzg.r-p1n3y5.r-sdzlij.r-1phboty.r-rs99b7.r-1loqt21.r-1w2pmg.r-1vsu8ta.r-aj3cln.r-1ny4l3l.r-1fneopy.r-o7ynqc.r-6416eg.r-lrvibr div.css-901oao.r-1awozwy.r-13gxpu9.r-6koalj.r-18u37iz.r-16y2uox.r-1qd0xha.r-a023e6.r-vw2c0b.r-1777fci.r-eljoum.r-dnmrzs.r-bcqeeo.r-q4m81j.r-qvutc0 span.css-901oao.css-16my406.css-bfa6kz.r-1qd0xha.r-ad9z0x.r-bcqeeo.r-qvutc0 span.css-901oao.css-16my406.r-1qd0xha.r-ad9z0x.r-bcqeeo.r-qvutc0\")\n",
    "girisYap.click()\n",
    "time.sleep(3)\n",
    "\n",
    "username = browser.find_element_by_css_selector(\"div.css-1dbjc4n:nth-child(6) > label:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > input:nth-child(1)\")\n",
    "password = browser.find_element_by_css_selector(\"div.css-1dbjc4n:nth-child(7) > label:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > input:nth-child(1)\")\n",
    "\n",
    "username.send_keys(\"veribilimiiu\")\n",
    "password.send_keys(\"veribilimi123\")\n",
    "time.sleep(3)\n",
    "\n",
    "login = browser.find_element_by_css_selector(\"span.css-bfa6kz > span:nth-child(1)\")\n",
    "login.click()\n",
    "time.sleep(5)\n",
    "\n",
    "searchArea = browser.find_element_by_css_selector(\".r-30o5oe\")\n",
    "searchButton = browser.find_element_by_css_selector(\"svg.r-18qmn74 > g:nth-child(1) > path:nth-child(1)\")\n",
    "\n",
    "searchArea.send_keys(\"#kadinasiddet\")\n",
    "searchArea.send_keys(Keys.ENTER)\n",
    "\n",
    "time.sleep(5)\n",
    "tweets = []\n",
    "\n",
    "lenOfPage=browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "match = False\n",
    "while(match == False):   \n",
    "    lastCount = lenOfPage\n",
    "    time.sleep(3)\n",
    "    elements = browser.find_elements_by_css_selector(\".css-901oao.r-hkyrab.r-1qd0xha.r-a023e6.r-16dba41.r-ad9z0x.r-bcqeeo.r-bnwqim.r-qvutc0\")\n",
    "    for element in elements:\n",
    "        tweets.append(element.text)\n",
    "    lenOfPage=browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "    \n",
    "    if lastCount == lenOfPage:\n",
    "        match = True\n",
    "time.sleep(5)\n",
    "\n",
    "tweetCount = 1\n",
    "\n",
    "with open(\"ProjeTweetsCounts.txt\",\"w\",encoding = \"UTF-8\") as file:\n",
    "    for tweet in tweets:\n",
    "        file.write(tweet + \"\\n\")\n",
    "        tweetCount += 1\n",
    "                   \n",
    "\n",
    "browser.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('turkish')) \n",
    "list(stop_words)[0:30]\n",
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "TemizTweets = []\n",
    "KelimeSayisi = []\n",
    "dosya = open(\"ProjeTweetsCounts.txt\",\"r\",encoding = \"UTF-8\").readlines()\n",
    "df = pd.DataFrame(dosya, columns=['Tweet'])\n",
    "for i in df['Tweet']:\n",
    "    i = strip_all_entities(strip_links(i))\n",
    "    i=i.lower()\n",
    "    TemizTweets.append(i.split()[:])\n",
    "    \n",
    "\n",
    "    \n",
    "df['TemizTweets']=TemizTweets\n",
    "df['TemizTweets']=df['TemizTweets'].apply(lambda x: [item for item in x if not item in stop_words])\n",
    "KelimeSayisi =[]\n",
    "sayi=len(df.iloc[:819].values)\n",
    "i=0\n",
    "for i in range(sayi):\n",
    "    satir = df['TemizTweets'][i]\n",
    "    kelime = len(satir)\n",
    "    KelimeSayisi.append(kelime)\n",
    "    \n",
    "df['KelimeSayisi']=KelimeSayisi\n",
    "\n",
    "\n",
    "sayi=len(df.iloc[:819].values)\n",
    "i=0\n",
    "for i in range(sayi):\n",
    "    if df['KelimeSayisi'][i] == 0:\n",
    "        df = df.drop(index=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Turkish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = pd.read_excel(\"STN.xlsx\")\n",
    "stn = stn.drop_duplicates(['synonyms']).set_index('synonyms')\n",
    "final_stn = {}\n",
    "for words in stn.index:\n",
    "    if words is np.nan:\n",
    "        continue\n",
    "    for word in words.split(\",\"):\n",
    "        final_stn[word.strip()] = {\"pos\":stn.loc[words][\"pos value\"], \"neg\":stn.loc[words][\"neg value\"], \"obj\":stn.loc[words][\"obj value\"] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skorlama(text):\n",
    "    pos_val = 0\n",
    "    neg_val = 0\n",
    "    obj_val = 0\n",
    "    for token in nlp(text):\n",
    "        word = token.text.lower()\n",
    "        if word in final_stn:\n",
    "            pos_val+=final_stn[word][\"pos\"]\n",
    "            neg_val+=final_stn[word][\"neg\"]\n",
    "            obj_val+=final_stn[word][\"obj\"]\n",
    "    return [pos_val, neg_val, obj_val]\n",
    "\n",
    "def skorlama_pos(text):\n",
    "    pos_val = 0\n",
    "    for token in nlp(text):\n",
    "        word = token.text.lower()\n",
    "        if word in final_stn:\n",
    "            pos_val+=final_stn[word][\"pos\"]\n",
    "    return [pos_val]\n",
    "\n",
    "def skorlama_neg(text):\n",
    "    neg_val = 0\n",
    "    for token in nlp(text):\n",
    "        word = token.text.lower()\n",
    "        if word in final_stn:\n",
    "            neg_val+=final_stn[word][\"neg\"]\n",
    "    return [neg_val]\n",
    "\n",
    "def skorlama_obj(text):\n",
    "    obj_val = 0\n",
    "    for token in nlp(text):\n",
    "        word = token.text.lower()\n",
    "        if word in final_stn:\n",
    "            obj_val+=final_stn[word][\"obj\"]\n",
    "    return [obj_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TemizTweets</th>\n",
       "      <th>KelimeSayisi</th>\n",
       "      <th>KelimePos</th>\n",
       "      <th>KelimeNeg</th>\n",
       "      <th>KelimeObj</th>\n",
       "      <th>TweetPos</th>\n",
       "      <th>TweetNeg</th>\n",
       "      <th>TweetObj</th>\n",
       "      <th>ToplamPos</th>\n",
       "      <th>ToplamNeg</th>\n",
       "      <th>ToplamObj</th>\n",
       "      <th>Sonuc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ülkede erkek neden en üstte?\\n</td>\n",
       "      <td>[ülkede, erkek, üstte]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0], [0.068], [0]]</td>\n",
       "      <td>[[0], [0.06], [0]]</td>\n",
       "      <td>[[0], [0.872], [0]]</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.290667</td>\n",
       "      <td>0.290667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Minibüste, evde ya da metrobüste\\n</td>\n",
       "      <td>[minibüste, evde, metrobüste]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0], [0], [0]]</td>\n",
       "      <td>[[0], [0.06], [0]]</td>\n",
       "      <td>[[0], [0.872], [0]]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.290667</td>\n",
       "      <td>0.290667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taciz şiddeti hiç bitmiyo'\\n</td>\n",
       "      <td>[taciz, şiddeti, bitmiyo]</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0], [0], [0]]</td>\n",
       "      <td>[[0], [0.06], [0]]</td>\n",
       "      <td>[[0], [0.872], [0]]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.290667</td>\n",
       "      <td>0.290667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kınamakla falan iş bitmiyo! #KadınaSiddet\\n</td>\n",
       "      <td>[kınamakla, falan, iş, bitmiyo]</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0], [0], [0.068], [0]]</td>\n",
       "      <td>[[0], [0.06], [0], [0]]</td>\n",
       "      <td>[[0], [0.872], [0], [0]]</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genelde toprak altına koyana kadar ceza almıyo...</td>\n",
       "      <td>[genelde, toprak, altına, koyana, kadar, ceza,...</td>\n",
       "      <td>11</td>\n",
       "      <td>[[0], [0.068], [0], [0], [0], [0.068], [0], [0...</td>\n",
       "      <td>[[0], [0.06], [0], [0], [0], [0], [0.964], [0]...</td>\n",
       "      <td>[[0], [0.872], [0], [0], [0], [0], [0.036], [0...</td>\n",
       "      <td>1.084</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.098545</td>\n",
       "      <td>0.093091</td>\n",
       "      <td>0.082545</td>\n",
       "      <td>0.098545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0                     Ülkede erkek neden en üstte?\\n   \n",
       "1                 Minibüste, evde ya da metrobüste\\n   \n",
       "2                       Taciz şiddeti hiç bitmiyo'\\n   \n",
       "3        Kınamakla falan iş bitmiyo! #KadınaSiddet\\n   \n",
       "4  Genelde toprak altına koyana kadar ceza almıyo...   \n",
       "\n",
       "                                         TemizTweets  KelimeSayisi  \\\n",
       "0                             [ülkede, erkek, üstte]             3   \n",
       "1                      [minibüste, evde, metrobüste]             3   \n",
       "2                          [taciz, şiddeti, bitmiyo]             3   \n",
       "3                    [kınamakla, falan, iş, bitmiyo]             4   \n",
       "4  [genelde, toprak, altına, koyana, kadar, ceza,...            11   \n",
       "\n",
       "                                           KelimePos  \\\n",
       "0                                [[0], [0.068], [0]]   \n",
       "1                                    [[0], [0], [0]]   \n",
       "2                                  [[0.0], [0], [0]]   \n",
       "3                           [[0], [0], [0.068], [0]]   \n",
       "4  [[0], [0.068], [0], [0], [0], [0.068], [0], [0...   \n",
       "\n",
       "                                           KelimeNeg  \\\n",
       "0                                 [[0], [0.06], [0]]   \n",
       "1                                 [[0], [0.06], [0]]   \n",
       "2                                 [[0], [0.06], [0]]   \n",
       "3                            [[0], [0.06], [0], [0]]   \n",
       "4  [[0], [0.06], [0], [0], [0], [0], [0.964], [0]...   \n",
       "\n",
       "                                           KelimeObj  TweetPos  TweetNeg  \\\n",
       "0                                [[0], [0.872], [0]]     0.068     0.060   \n",
       "1                                [[0], [0.872], [0]]     0.000     0.060   \n",
       "2                                [[0], [0.872], [0]]     0.000     0.060   \n",
       "3                           [[0], [0.872], [0], [0]]     0.068     0.060   \n",
       "4  [[0], [0.872], [0], [0], [0], [0], [0.036], [0...     1.084     1.024   \n",
       "\n",
       "   TweetObj  ToplamPos  ToplamNeg  ToplamObj     Sonuc  \n",
       "0     0.872   0.022667   0.020000   0.290667  0.290667  \n",
       "1     0.872   0.000000   0.020000   0.290667  0.290667  \n",
       "2     0.872   0.000000   0.020000   0.290667  0.290667  \n",
       "3     0.872   0.017000   0.015000   0.218000  0.218000  \n",
       "4     0.908   0.098545   0.093091   0.082545  0.098545  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=[]\n",
    "neg=[]\n",
    "obj=[]\n",
    "for j in df['TemizTweets']:\n",
    "    for i in j:\n",
    "        skor=skorlama_pos(i)\n",
    "        pos.append(skor)\n",
    "        skor2=skorlama_neg(i)\n",
    "        neg.append(skor2)\n",
    "        skor3=skorlama_obj(i)\n",
    "        obj.append(skor3)\n",
    "        \n",
    "sayi=[]\n",
    "for i in df['KelimeSayisi']:\n",
    "    sayi.append(i)\n",
    "\n",
    "pos2=[]\n",
    "neg2=[]\n",
    "obj2=[]\n",
    "for i in sayi:\n",
    "    pos2.append(pos[:i])\n",
    "    neg2.append(neg[:i])\n",
    "    obj2.append(obj[:i])\n",
    "    del pos[:i]\n",
    "    \n",
    "df['KelimePos']=pos2\n",
    "df['KelimeNeg']=neg2\n",
    "df['KelimeObj']=obj2\n",
    "\n",
    "deger=[]\n",
    "liste=df['KelimePos']\n",
    "liste2=df['KelimeNeg']\n",
    "deger2=[]\n",
    "liste3=df['KelimeObj']\n",
    "deger3=[]\n",
    "for i in liste:\n",
    "    deger.append(sum(sum(i, [])))\n",
    "    \n",
    "for i in liste2:\n",
    "    deger2.append(sum(sum(i, [])))\n",
    "    \n",
    "for i in liste3:\n",
    "    deger3.append(sum(sum(i, [])))\n",
    "    \n",
    "\n",
    "\n",
    "df['TweetPos']=deger\n",
    "df['TweetNeg']=deger2\n",
    "df['TweetObj']=deger3\n",
    "\n",
    "\n",
    "\n",
    "ToplamPos=df['TweetPos']/df['KelimeSayisi']\n",
    "df['ToplamPos']=ToplamPos\n",
    "ToplamNeg=df['TweetNeg']/df['KelimeSayisi']\n",
    "df['ToplamNeg']=ToplamNeg\n",
    "ToplamObj=df['TweetObj']/df['KelimeSayisi']\n",
    "df['ToplamObj']=ToplamObj\n",
    "\n",
    "\n",
    "Sonuc= df[[\"ToplamPos\", \"ToplamNeg\", \"ToplamObj\"]].max(axis=1)\n",
    "\n",
    "df['Sonuc']=Sonuc\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "durum=[]\n",
    "durum2=[]\n",
    "durum3=[]\n",
    "kod=df['ToplamObj']==df['Sonuc']\n",
    "kod2=df['ToplamPos']==df['Sonuc']\n",
    "kod3=df['ToplamNeg']==df['Sonuc']\n",
    "for i in kod:\n",
    "    if i==True:\n",
    "        durum.append(\"obj\")\n",
    "    else:\n",
    "        pass\n",
    "for i in kod2:\n",
    "    if i==True:\n",
    "        durum2.append(\"pos\")\n",
    "    else:\n",
    "        pass\n",
    "for i in kod3:\n",
    "    if i==True:\n",
    "        durum3.append(\"neg\")\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
